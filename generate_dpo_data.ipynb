{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPO Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "train_data_path = Path(\"data/sentiment_analysis/cleaned_ds_train.json\")\n",
    "validation_data_path = Path(\"data/sentiment_analysis/cleaned_ds_validation.json\")\n",
    "\n",
    "with open(train_data_path, \"r\") as f:\n",
    "    train_data = json.load(f)\n",
    "    print(f\"There are {len(train_data)} training samples\")\n",
    "\n",
    "with open(validation_data_path, \"r\") as f:\n",
    "    validation_data = json.load(f)\n",
    "    print(f\"There are {len(validation_data)} validation samples\")\n",
    "\n",
    "def ticker_data_map(data):\n",
    "    import re\n",
    "    ticker_map = {}\n",
    "    for item in data:\n",
    "        x = item['text']\n",
    "        x = re.sub(r'https?://\\S+', '', x)\n",
    "        stock_ticket = re.search(r'\\$([A-Z]+)', x)\n",
    "        if stock_ticket:\n",
    "            ticker = stock_ticket.group(1)\n",
    "            if ticker not in ticker_map:\n",
    "                ticker_map[ticker] = []\n",
    "            ticker_map[ticker].append(item)\n",
    "    return ticker_map\n",
    "\n",
    "train_ticker_map = ticker_data_map(train_data)\n",
    "validation_ticker_map = ticker_data_map(validation_data)\n",
    "\n",
    "print(f\"There are {len(train_ticker_map)} training tickers\")\n",
    "print(f\"There are {len(validation_ticker_map)} validation tickers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = Path(\"prompt_templates/train_synthesis/dpo.txt\").read_text()\n",
    "sentiment_map = {0: \"bearish (0)\", 1: \"bullish (1)\", 2: \"neutral (2)\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "\n",
    "synthetic_data_path = Path(\"qwen2.5-instruct_original_prompt=zero-shot_bg_train-time-info_v2.json\")\n",
    "\n",
    "with open(synthetic_data_path, \"r\") as f:\n",
    "    synthetic_data = json.load(f)\n",
    "\n",
    "def process_sentiment(sentiment):\n",
    "    lowered = sentiment.lower()\n",
    "    if \"bullish\" in lowered or \"1\" in lowered:\n",
    "        return 1\n",
    "    elif \"bearish\" in lowered or \"0\" in lowered:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "synthetic_ticker_sentiment_map = {} # ticker -> sentiment -> headline\n",
    "for item in synthetic_data:\n",
    "    headline = item[\"headline\"]\n",
    "    sentiment = item[\"sentiment\"]\n",
    "    processed_sentiment = process_sentiment(sentiment)\n",
    "    ticker = re.search(r'\\$([A-Z]+)', headline)\n",
    "    if ticker:\n",
    "        ticker = ticker.group(1)\n",
    "        if ticker not in synthetic_ticker_sentiment_map:\n",
    "            synthetic_ticker_sentiment_map[ticker] = {}\n",
    "        synthetic_ticker_sentiment_map[ticker][processed_sentiment] = item\n",
    "\n",
    "synthetic_ticker_sentiment_map['NVDA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dpo_messages(input_id, prompt, chosen_targets, rejected_targets):\n",
    "    chosen_messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": chosen_targets}\n",
    "    ]\n",
    "    rejected_messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": rejected_targets}\n",
    "    ]\n",
    "\n",
    "    return {\"id\": input_id, \"prompt\": prompt, \"chosen\": chosen_messages, \"rejected\": rejected_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_data_list = []\n",
    "\n",
    "ticker_counter = 0\n",
    "for ticker, data in train_ticker_map.items():\n",
    "    if ticker not in synthetic_ticker_sentiment_map:\n",
    "        continue\n",
    "    for i, item in enumerate(data):\n",
    "        target = item[\"text\"]\n",
    "        label = item[\"label\"]\n",
    "        if label not in synthetic_ticker_sentiment_map[ticker]:\n",
    "            continue\n",
    "        input_prompt = prompt_template.replace(\"{stock_ticker}\", f\"${ticker}\").replace(\"{sentiment}\", sentiment_map[label])\n",
    "        json_target = json.dumps({\"headline\": target, \"sentiment\": label})\n",
    "        synthetic_target = json.dumps(synthetic_ticker_sentiment_map[ticker][label])\n",
    "        dpo_data = generate_dpo_messages(f\"data_synthesis_dpo_ticker_{ticker_counter}_{i}\", \n",
    "                                         input_prompt, json_target, synthetic_target)\n",
    "        dpo_data_list.append(dpo_data)\n",
    "    ticker_counter += 1\n",
    "print(f\"Total DPO data: {len(dpo_data_list)}\")\n",
    "dpo_data_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Convert the list of dictionaries to a Dataset\n",
    "dpo_dataset = Dataset.from_list(dpo_data_list)\n",
    "\n",
    "# Create a DatasetDict if you have multiple splits (e.g., train, validation)\n",
    "dataset_dict = DatasetDict({\"train\": dpo_dataset})\n",
    "\n",
    "# Push the dataset to Hugging Face Hub\n",
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = \"\"\n",
    "dataset_dict.push_to_hub(\"ArthurChen189/financial_news_sentiment_analysis_dpo\", private=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = Path(\"prompt_templates/train_synthesis/sft.txt\").read_text()\n",
    "\n",
    "\n",
    "def generate_sft_data(input_id, prompt, target):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": target}\n",
    "    ]\n",
    "    return {\"id\": input_id, \"messages\": messages}\n",
    "\n",
    "sft_data_list = []\n",
    "\n",
    "ticker_counter = 0\n",
    "for ticker, data in train_ticker_map.items():\n",
    "    for i, item in enumerate(data):\n",
    "        target = item[\"text\"]\n",
    "        label = item[\"label\"]\n",
    "        # input_prompt = prompt_template.format(stock_ticker=f\"${ticker}\", sentiment=sentiment_map[label])\n",
    "        input_prompt = prompt_template.replace(\"{stock_ticker}\", f\"${ticker}\").replace(\"{sentiment}\", sentiment_map[label])\n",
    "        json_target = json.dumps({\"headline\": target, \"sentiment\": label})\n",
    "        sft_data = generate_sft_data(f\"data_synthesis_sft_ticker_{ticker_counter}_{i}\", input_prompt, json_target)\n",
    "        sft_data_list.append(sft_data)\n",
    "    ticker_counter += 1\n",
    "\n",
    "sft_data_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Convert the list of dictionaries to a Dataset\n",
    "sft_dataset = Dataset.from_list(sft_data_list)\n",
    "\n",
    "# Create a DatasetDict if you have multiple splits (e.g., train, validation)\n",
    "dataset_dict = DatasetDict({\"train\": sft_dataset})\n",
    "\n",
    "# Push the dataset to Hugging Face Hub\n",
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = \"<>\"\n",
    "dataset_dict.push_to_hub(\"ArthurChen189/financial_news_sentiment_analysis_sft\", private=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import json\n",
    "real_test_data = json.load(open(\"data/sentiment_analysis/cleaned_ds_validation.json\"))\n",
    "\n",
    "original_synthetic_data = json.load(open(\"qwen2.5-instruct_original_prompt=zero-shot_bg_test-time-info_v2.json\"))\n",
    "sft_synthetic_data = json.load(open(\"qwen2.5-instruct_sft_prompt=zero-shot_bg_test-time-info_v2.json\"))\n",
    "dpo_synthetic_data = json.load(open(\"qwen2.5-instruct_dpo_prompt=zero-shot_bg_test-time-info_v2.json\"))\n",
    "\n",
    "\n",
    "# --- preprocess sentiment ---\n",
    "def preprocess_data(data, x_key, y_key):\n",
    "    def process_sentiment(sentiment):\n",
    "        lowered = str(sentiment).lower()\n",
    "        if \"bullish\" in lowered or \"1\" in lowered:\n",
    "            return 1\n",
    "        elif \"bearish\" in lowered or \"0\" in lowered:\n",
    "            return 0\n",
    "        else:\n",
    "            return 2\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    for item in data:\n",
    "        inputs.append(str(item[x_key]))\n",
    "        labels.append(process_sentiment(item[y_key]))\n",
    "    return inputs, labels\n",
    "\n",
    "real_test_data_inputs, real_test_data_labels = preprocess_data(real_test_data, 'text', 'label')\n",
    "original_synthetic_data_inputs, original_synthetic_data_labels = preprocess_data(original_synthetic_data, 'headline', 'sentiment')\n",
    "sft_synthetic_data_inputs, sft_synthetic_data_labels = preprocess_data(sft_synthetic_data, 'headline', 'sentiment')\n",
    "dpo_synthetic_data_inputs, dpo_synthetic_data_labels = preprocess_data(dpo_synthetic_data, 'headline', 'sentiment')\n",
    "\n",
    "error_index = 981\n",
    "sft_synthetic_data_inputs.pop(error_index)\n",
    "sft_synthetic_data_labels.pop(error_index)\n",
    "\n",
    "# make sure the number of synthetic data is the same\n",
    "dpo_synthetic_data_inputs.pop(0) \n",
    "dpo_synthetic_data_labels.pop(0)\n",
    "\n",
    "original_synthetic_data_inputs.pop(0)\n",
    "original_synthetic_data_labels.pop(0)\n",
    "\n",
    "print(f\"There are {len(real_test_data_inputs)} real test data\")\n",
    "print(f\"There are {len(original_synthetic_data_inputs)} original synthetic data\")\n",
    "print(f\"There are {len(sft_synthetic_data_inputs)} sft synthetic data\")\n",
    "print(f\"There are {len(dpo_synthetic_data_inputs)} dpo synthetic data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import auto as tqdm\n",
    "# sentence_model_name = 'joe32140/ModernBERT-large-msmarco'\n",
    "powerful_model = 'intfloat/e5-small-v2'\n",
    "sentence_model = SentenceTransformer(powerful_model)\n",
    "\n",
    "emb_real = sentence_model.encode(real_test_data_inputs)\n",
    "original_emb_synth = sentence_model.encode(original_synthetic_data_inputs)\n",
    "sft_emb_synth = sentence_model.encode(sft_synthetic_data_inputs)\n",
    "dpo_emb_synth = sentence_model.encode(dpo_synthetic_data_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "params = {\n",
    "    'objective': 'multi:softmax', # Change to multiclass classification\n",
    "    'eval_metric': 'mlogloss',    # Change metric for multiclass\n",
    "    'num_class': 3                # Specify number of classes (0,1,2)\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "dtest = xgb.DMatrix(emb_real, label=real_test_data_labels)\n",
    "\n",
    "# Train on original synthetic data\n",
    "original_training_results = []\n",
    "dtrain = xgb.DMatrix(original_emb_synth, label=original_synthetic_data_labels)\n",
    "for i, (train_index, val_index) in enumerate(kf.split(original_emb_synth)):\n",
    "    dtrain = xgb.DMatrix(original_emb_synth[train_index], label=np.array(original_synthetic_data_labels)[train_index])\n",
    "    dval = xgb.DMatrix(original_emb_synth[val_index], label=np.array(original_synthetic_data_labels)[val_index])\n",
    "    m = xgb.train(\n",
    "        params, dtrain,\n",
    "        num_boost_round=100,\n",
    "        early_stopping_rounds=10,\n",
    "        evals=[(dval, 'validation')],\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "    original_training_results.append(dict(\n",
    "        fold=i,\n",
    "        dataset='original',\n",
    "        model=m,\n",
    "        train_acc=np.mean(m.predict(dtrain)==np.array(original_synthetic_data_labels)[train_index]),\n",
    "        val_acc=np.mean(m.predict(dval)==np.array(original_synthetic_data_labels)[val_index]),\n",
    "        test_acc=np.mean(m.predict(dtest)==np.array(real_test_data_labels)),\n",
    "    ))\n",
    "\n",
    "# Train on SFT synthetic data\n",
    "sft_training_results = []\n",
    "dtrain = xgb.DMatrix(sft_emb_synth, label=sft_synthetic_data_labels)\n",
    "for i, (train_index, val_index) in enumerate(kf.split(sft_emb_synth)):\n",
    "    dtrain = xgb.DMatrix(sft_emb_synth[train_index], label=np.array(sft_synthetic_data_labels)[train_index])\n",
    "    dval = xgb.DMatrix(sft_emb_synth[val_index], label=np.array(sft_synthetic_data_labels)[val_index])\n",
    "    m = xgb.train(\n",
    "        params, dtrain,\n",
    "        num_boost_round=100,\n",
    "        early_stopping_rounds=10,\n",
    "        evals=[(dval, 'validation')],\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "    sft_training_results.append(dict(\n",
    "        fold=i,\n",
    "        dataset='sft',\n",
    "        model=m,\n",
    "        train_acc=np.mean(m.predict(dtrain)==np.array(sft_synthetic_data_labels)[train_index]),\n",
    "        val_acc=np.mean(m.predict(dval)==np.array(sft_synthetic_data_labels)[val_index]),\n",
    "        test_acc=np.mean(m.predict(dtest)==np.array(real_test_data_labels)),\n",
    "    ))\n",
    "\n",
    "# Train on DPO synthetic data\n",
    "dpo_training_results = []\n",
    "dtrain = xgb.DMatrix(dpo_emb_synth, label=dpo_synthetic_data_labels)\n",
    "for i, (train_index, val_index) in enumerate(kf.split(dpo_emb_synth)):\n",
    "    dtrain = xgb.DMatrix(dpo_emb_synth[train_index], label=np.array(dpo_synthetic_data_labels)[train_index])\n",
    "    dval = xgb.DMatrix(dpo_emb_synth[val_index], label=np.array(dpo_synthetic_data_labels)[val_index])\n",
    "    m = xgb.train(\n",
    "        params, dtrain,\n",
    "        num_boost_round=100,\n",
    "        early_stopping_rounds=10,\n",
    "        evals=[(dval, 'validation')],\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "    dpo_training_results.append(dict(\n",
    "        fold=i,\n",
    "        dataset='dpo',\n",
    "        model=m,\n",
    "        train_acc=np.mean(m.predict(dtrain)==np.array(dpo_synthetic_data_labels)[train_index]),\n",
    "        val_acc=np.mean(m.predict(dval)==np.array(dpo_synthetic_data_labels)[val_index]),\n",
    "        test_acc=np.mean(m.predict(dtest)==np.array(real_test_data_labels)),\n",
    "    ))\n",
    "\n",
    "# Combine results\n",
    "training_results = sft_training_results + dpo_training_results + original_training_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame for visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Extract relevant metrics from training results\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        'dataset': result['dataset'],\n",
    "        'fold': result['fold'],\n",
    "        'test_accuracy': result['test_acc']\n",
    "    }\n",
    "    for result in training_results\n",
    "])\n",
    "\n",
    "# Calculate summary statistics\n",
    "summary_df = results_df.groupby('dataset')['test_accuracy'].agg(['mean', 'std', 'min', 'max']).reset_index()\n",
    "print(\"Summary Statistics:\")\n",
    "display(summary_df)\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(x='dataset', y='test_accuracy', data=results_df)\n",
    "sns.stripplot(x='dataset', y='test_accuracy', data=results_df, color='black', size=4, jitter=True)\n",
    "\n",
    "plt.title('Test Accuracy Comparison on Real Data')\n",
    "plt.xlabel('Training Dataset')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('test_accuracy_boxplot.png')\n",
    "plt.show()\n",
    "\n",
    "# Create a bar chart with error bars - fixed to avoid ValueError with yerr\n",
    "plt.figure(figsize=(6, 4))\n",
    "# Plot each bar individually to avoid the yerr shape mismatch\n",
    "for i, row in summary_df.iterrows():\n",
    "    plt.bar(i, row['mean'], yerr=row['std'], capsize=0.2)\n",
    "\n",
    "plt.xticks(range(len(summary_df)), summary_df['dataset'])\n",
    "plt.title('Average Test Accuracy with Standard Deviation')\n",
    "plt.xlabel('Training Dataset')\n",
    "plt.ylabel('Test Accuracy (mean)')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('test_accuracy_barchart.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-synthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
